
## üöÄ  Projeto de Data Science: Previs√£o de Convers√£o de Marketing (Lead Scoring)
Este √© um projeto completo de Ci√™ncia de Dados focado em prever a convers√£o de clientes (Lead Scoring) com base em dados de uma campanha de marketing de um banco.

O objetivo principal √© construir um modelo de Machine Learning que possa identificar quais clientes t√™m a maior probabilidade de converter (subscrever um produto) ap√≥s serem contactados pela equipa de marketing. Prever se um cliente do CRM, contactado por uma campanha de marketing, ir√° converter (ou seja, comprar um produto ou subscrever um servi√ßo).


## üéØ O Problema de Neg√≥cio
Uma equipa de marketing tem um or√ßamento e tempo limitados. Contactar todos os clientes da base de dados √© caro e ineficiente. A maioria dos clientes contactados n√£o ir√° converter, resultando em desperd√≠cio de recursos.

O pior erro, no entanto, √© um Falso Negativo: um cliente que o modelo previu como "N√£o" (n√£o converte), mas que na realidade iria converter. Esta √© uma venda perdida.

O objetivo deste projeto √© criar um modelo que minimize os Falsos Negativos, aumentando o Recall (a capacidade de "apanhar" todos os clientes que realmente iriam converter), para que a equipa de marketing possa focar os seus esfor√ßos nos leads mais promissores.


## üìä O Dataset
Utiliz√°mos o Bank Marketing Dataset (Bank Additional Full), um conjunto de dados p√∫blico e popular para problemas de classifica√ß√£o.

Este dataset cont√©m 41.188 registos de clientes e 20 colunas, incluindo:

Dados Demogr√°ficos: age, job, marital, education.

Dados da Campanha: contact, month, day_of_week, duration (dura√ß√£o da chamada).

Hist√≥rico: pdays, previous, poutcome.

Vari√°veis Econ√≥micas: emp.var.rate, cons.price.idx.

Vari√°vel Alvo: y - O cliente subscreveu o dep√≥sito a prazo? ('yes' ou 'no').


##  üõ†Ô∏è Ferramentas Utilizadas
Python (3.x)

Jupyter Notebook: Para explora√ß√£o e prototipagem interativa.

Pandas: Para manipula√ß√£o e carregamento dos dados.

Scikit-learn (sklearn): Para todo o fluxo de Machine Learning.


##  üìà Metodologia (O Processo)
O projeto seguiu os passos cl√°ssicos de um fluxo de trabalho de Machine Learning:

Carregamento e Explora√ß√£o: Os dados foram carregados e analisados. Verific√°mos que o dataset estava limpo (sem valores nulos) e que o nosso alvo (y) era altamente desbalanceado (~89% 'no' vs. ~11% 'yes').

Pr√©-processamento:

Features Categ√≥ricas: Aplic√°mos OneHotEncoder para transformar colunas de texto (como job ou marital) em colunas num√©ricas (0s e 1s).

Features Num√©ricas: Aplic√°mos StandardScaler para normalizar as colunas num√©ricas (como age), colocando-as na mesma escala.

Pipeline: Todo o pr√©-processamento foi encapsulado num ColumnTransformer e, por sua vez, numa Pipeline do Scikit-learn para evitar data leakage (fuga de dados) e otimizar o fluxo.

Modelo 1 (Baseline): Regress√£o Log√≠stica

Cri√°mos um primeiro modelo simples usando LogisticRegression.

Resultado: A acur√°cia foi alta (~91%), mas a Matriz de Confus√£o revelou o problema: o modelo tinha um n√∫mero muito elevado de Falsos Negativos. Ele estava "viciado" em dizer 'N√£o' devido ao desbalanceamento dos dados.

Modelo 2 (Otimizado): Random Forest com Balanceamento

Para resolver o problema dos Falsos Negativos, troc√°mos o algoritmo para um RandomForestClassifier, que √© mais poderoso.

A "Magia": Us√°mos o par√¢metro class_weight='balanced'. Isto for√ßa o modelo a dar um "peso" (penaliza√ß√£o) muito maior ao erro de classificar um 'yes' como 'no'.

Resultado: O modelo final sacrificou um pouco da precis√£o (Precision) para ganhar um aumento dr√°stico no Recall (capacidade de encontrar os 'yes').


##  üí° Principais Insights e Conclus√µes
A Acur√°cia pode enganar: O nosso primeiro modelo tinha 91% de acur√°cia, mas era p√©ssimo para o neg√≥cio. O segundo modelo, focado no Recall, √© muito mais valioso, pois encontra de facto as oportunidades de venda.

O Problema dos Falsos Negativos: Este projeto demonstrou como a Matriz de Confus√£o √© vital. Focar na redu√ß√£o de Falsos Negativos (oportunidades perdidas) foi a chave para o sucesso.

Valor para o Neg√≥cio: Este modelo final pode agora ser usado para criar um score (pontua√ß√£o) para cada novo cliente. A equipa de marketing pode filtrar a base de dados e focar os seus esfor√ßos apenas nos clientes com uma probabilidade de convers√£o acima de X%, otimizando drasticamente o ROI (Retorno sobre o Investimento) das campanhas.


##  üöÄ Pr√≥ximos Passos
Feature Importance: Analisar quais vari√°veis (duration, age, poutcome?) s√£o as mais importantes para a previs√£o do modelo RandomForest.

Hyperparameter Tuning: Usar GridSearchCV ou RandomizedSearchCV para encontrar os melhores par√¢metros para o RandomForest e otimizar ainda mais o Recall.

Outros Modelos: Testar algoritmos de Gradient Boosting (como XGBoost ou LightGBM), que s√£o frequentemente os vencedores em competi√ß√µes de dados tabulares.
